{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1dfa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "!pip install surya-ocr transformers datasets accelerate -q\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NOT FOUND'}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695af54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your data path (update this to your actual path)\n",
    "DATA_PATH = \"/content/drive/MyDrive/OCR_Bangla/training/data\"\n",
    "\n",
    "import os\n",
    "print(f\"\\nChecking data path: {DATA_PATH}\")\n",
    "if os.path.exists(DATA_PATH):\n",
    "    print(\"‚úì Data path found!\")\n",
    "    print(f\"  Images: {len(os.listdir(os.path.join(DATA_PATH, 'raw')))} files\")\n",
    "else:\n",
    "    print(\"‚úó Data path NOT found!\")\n",
    "    print(\"  Please upload your training/data folder to Google Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17379a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load training data\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def load_nid_dataset(data_path):\n",
    "    \"\"\"Load NID OCR training data from folder.\"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    images_dir = data_path / \"raw\"\n",
    "    labels_file = data_path / \"annotations\" / \"labels.txt\"\n",
    "    \n",
    "    # Load labels\n",
    "    labels = {}\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if '\\t' in line:\n",
    "                parts = line.split('\\t', 1)\n",
    "                if len(parts) == 2:\n",
    "                    labels[parts[0]] = parts[1]\n",
    "    \n",
    "    # Create dataset\n",
    "    samples = []\n",
    "    for img_name, text in labels.items():\n",
    "        img_path = images_dir / img_name\n",
    "        if img_path.exists() and text.strip():\n",
    "            samples.append({\n",
    "                \"image_path\": str(img_path),\n",
    "                \"text\": text.strip(),\n",
    "            })\n",
    "    \n",
    "    print(f\"Loaded {len(samples)} samples\")\n",
    "    \n",
    "    # Split 90/10\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    random.shuffle(samples)\n",
    "    split_idx = int(len(samples) * 0.9)\n",
    "    \n",
    "    train_data = samples[:split_idx]\n",
    "    val_data = samples[split_idx:]\n",
    "    \n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}\")\n",
    "    \n",
    "    return {\n",
    "        \"train\": Dataset.from_list(train_data),\n",
    "        \"val\": Dataset.from_list(val_data),\n",
    "    }\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_nid_dataset(DATA_PATH)\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample data:\")\n",
    "for i, sample in enumerate(dataset[\"train\"]):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"  {sample['text'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize Surya model\n",
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "\n",
    "print(\"Loading Surya OCR model...\")\n",
    "foundation = FoundationPredictor()\n",
    "rec_predictor = RecognitionPredictor(foundation)\n",
    "\n",
    "print(\"‚úì Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91789e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Test model BEFORE fine-tuning\n",
    "from PIL import Image\n",
    "\n",
    "# Test on first few training images\n",
    "print(\"Testing model BEFORE fine-tuning:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, sample in enumerate(dataset[\"train\"]):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    \n",
    "    img = Image.open(sample[\"image_path\"])\n",
    "    results = rec_predictor([img], [\"bn\", \"en\"])\n",
    "    \n",
    "    pred_text = \" \".join([line.text for line in results[0].text_lines]) if results else \"\"\n",
    "    \n",
    "    print(f\"\\n[{i+1}] Ground truth: {sample['text']}\")\n",
    "    print(f\"    Prediction:   {pred_text}\")\n",
    "    match = \"‚úì\" if pred_text.strip() == sample['text'].strip() else \"‚úó\"\n",
    "    print(f\"    Match: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Run Fine-tuning using official Surya script\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Save dataset in HuggingFace format\n",
    "OUTPUT_DIR = \"/content/surya_bangla_finetuned\"\n",
    "DATASET_DIR = \"/content/bangla_nid_dataset\"\n",
    "\n",
    "# Create local dataset copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.makedirs(f\"{DATASET_DIR}/images\", exist_ok=True)\n",
    "\n",
    "# Copy images and create proper format\n",
    "train_data = []\n",
    "for sample in dataset[\"train\"]:\n",
    "    src = sample[\"image_path\"]\n",
    "    dst = f\"{DATASET_DIR}/images/{os.path.basename(src)}\"\n",
    "    shutil.copy(src, dst)\n",
    "    train_data.append({\n",
    "        \"image\": f\"images/{os.path.basename(src)}\",\n",
    "        \"text\": sample[\"text\"]\n",
    "    })\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{DATASET_DIR}/metadata.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in train_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Dataset prepared at {DATASET_DIR}\")\n",
    "print(f\"Total samples: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Find and run official Surya fine-tune script\n",
    "import surya\n",
    "from pathlib import Path\n",
    "\n",
    "surya_path = Path(surya.__file__).parent\n",
    "finetune_script = surya_path / \"scripts\" / \"finetune_ocr.py\"\n",
    "\n",
    "print(f\"Surya path: {surya_path}\")\n",
    "print(f\"Finetune script exists: {finetune_script.exists()}\")\n",
    "\n",
    "if finetune_script.exists():\n",
    "    # Read the script to understand its arguments\n",
    "    !head -100 \"{finetune_script}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984db2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Alternative - Custom training loop\n",
    "# Use this if official script doesn't work with local dataset\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom training function\n",
    "def train_surya_bangla(dataset, rec_predictor, num_epochs=10, batch_size=8, lr=5e-5):\n",
    "    \"\"\"\n",
    "    Simple fine-tuning loop for Surya OCR.\n",
    "    Note: Full fine-tuning requires access to internal model structure.\n",
    "    This is a simplified demonstration.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting training...\")\n",
    "    print(f\"  Epochs: {num_epochs}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Learning rate: {lr}\")\n",
    "    \n",
    "    # Get the underlying model\n",
    "    model = rec_predictor.model\n",
    "    model.train()\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Process in batches\n",
    "        samples = list(dataset[\"train\"])\n",
    "        for i in tqdm(range(0, len(samples), batch_size), desc=f\"Epoch {epoch+1}\"):\n",
    "            batch_samples = samples[i:i+batch_size]\n",
    "            \n",
    "            # Load images\n",
    "            images = [Image.open(s[\"image_path\"]) for s in batch_samples]\n",
    "            texts = [s[\"text\"] for s in batch_samples]\n",
    "            \n",
    "            # Forward pass (simplified - actual implementation varies)\n",
    "            # This is a placeholder - real fine-tuning needs model internals\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Note: Actual loss computation requires tokenized targets\n",
    "            # and proper model forward with labels\n",
    "            \n",
    "            num_batches += 1\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} complete\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  For full Surya fine-tuning, use the official script:\")\n",
    "print(\"python -m surya.scripts.finetune_ocr --help\")\n",
    "print(\"\\nOr contact hi@datalab.to for their internal training stack.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Upload dataset to HuggingFace Hub for official fine-tuning\n",
    "from huggingface_hub import notebook_login, HfApi\n",
    "\n",
    "# Login to HuggingFace\n",
    "notebook_login()\n",
    "\n",
    "# Upload dataset\n",
    "api = HfApi()\n",
    "\n",
    "# Create dataset repo (change 'your-username' to your actual username)\n",
    "DATASET_REPO = \"your-username/bangla-nid-ocr\"  # UPDATE THIS!\n",
    "\n",
    "print(f\"\\nTo upload your dataset to HuggingFace:\")\n",
    "print(f\"1. Update DATASET_REPO with your username\")\n",
    "print(f\"2. Run: api.upload_folder(folder_path='{DATASET_DIR}', repo_id='{DATASET_REPO}', repo_type='dataset')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Run official Surya fine-tuning (after uploading dataset)\n",
    "\n",
    "# UNCOMMENT and UPDATE these lines after uploading dataset to HuggingFace:\n",
    "\n",
    "# !python -m surya.scripts.finetune_ocr \\\n",
    "#     --output_dir /content/surya_bangla_finetuned \\\n",
    "#     --dataset_name your-username/bangla-nid-ocr \\\n",
    "#     --per_device_train_batch_size 8 \\\n",
    "#     --gradient_checkpointing true \\\n",
    "#     --max_sequence_length 512 \\\n",
    "#     --num_train_epochs 50 \\\n",
    "#     --learning_rate 5e-5 \\\n",
    "#     --save_steps 500 \\\n",
    "#     --logging_steps 50\n",
    "\n",
    "print(\"Update DATASET_REPO and uncomment the command above to start training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c228ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Test AFTER fine-tuning\n",
    "# Run this after training completes\n",
    "\n",
    "# Load fine-tuned model\n",
    "# rec_predictor_finetuned = RecognitionPredictor(\n",
    "#     foundation,\n",
    "#     model_path=\"/content/surya_bangla_finetuned/final\"\n",
    "# )\n",
    "\n",
    "# Test on same images\n",
    "# print(\"Testing model AFTER fine-tuning:\")\n",
    "# ... same testing code as Step 5 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Download fine-tuned model\n",
    "# Run after training to save model to Google Drive\n",
    "\n",
    "# !cp -r /content/surya_bangla_finetuned \"/content/drive/MyDrive/OCR_Bangla/models/\"\n",
    "# print(\"Model saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25607eff",
   "metadata": {},
   "source": [
    "## üìã Summary\n",
    "\n",
    "### What this notebook does:\n",
    "1. Loads your NID training data (images + Bangla labels)\n",
    "2. Tests Surya OCR **before** fine-tuning\n",
    "3. Prepares dataset in HuggingFace format\n",
    "4. Runs fine-tuning with official Surya script\n",
    "5. Tests Surya OCR **after** fine-tuning\n",
    "6. Saves fine-tuned model to Google Drive\n",
    "\n",
    "### To use the fine-tuned model locally:\n",
    "```python\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.foundation import FoundationPredictor\n",
    "\n",
    "foundation = FoundationPredictor()\n",
    "rec = RecognitionPredictor(\n",
    "    foundation,\n",
    "    model_path=\"models/surya_bangla_finetuned\"\n",
    ")\n",
    "\n",
    "results = rec([image], [\"bn\", \"en\"])\n",
    "```\n",
    "\n",
    "### Tips:\n",
    "- More training data = better results\n",
    "- Aim for 500+ labeled samples\n",
    "- Include variety in NID conditions\n",
    "- Training takes ~2 hours on T4 GPU"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
